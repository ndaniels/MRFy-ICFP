
\documentclass[preprint]{sigplanconf}

% The following \documentclass options may be useful:
%
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.

\usepackage{amsmath}
\usepackage{array}
\usepackage{listings}
\usepackage{graphicx}
\lstset{
    tabsize = 2,
    basicstyle = \ttfamily,
    language = Haskell
    }    

\begin{document}


\conferenceinfo{ICFP '12}{September 9-15, Copenhagen.} 
\copyrightyear{2012} 
\copyrightdata{[to be supplied]} 

\titlebanner{banner above paper title}        % These are ignored unless
\preprintfooter{short description of paper}   % 'preprint' option specified.

\title{Experience Report: Haskell in Computational Biology}
% \subtitle{Subtitle Text, if any}

\authorinfo{Noah M. Daniels \and Andrew Gallant \and Norman Ramsey}
           {Department of Computer Science, Tufts University}
           {\{ndaniels, agallant, nr\}@cs.tufts.edu}


\maketitle

\begin{abstract}
This is the text of the abstract.
\end{abstract}

\category{CR-number}{subcategory}{third-level}

\terms
term1, term2

\keywords
keyword1, keyword2

\section{Introduction}

We address this paper to computational biologists who may have an interest in 
functional programming, but this is not an advocacy paper. We do not argue that 
computational biologists \textit{should} use functional programming. Rather, 
argue that computational biologists \textit{can} successfully develop software 
in Haskell, and what to expect if they do.

We also address this paper to the functional programming community, in the 
hopes that our experiences will be enlightening. We believe that our 
experiences can provide lessons about outreach and education.


\subsection{Problem Domain}

Computational biologists write software that answers questions about large data 
sets involving sequences of nucleic acids (genomic data) or sequences of amino 
acids (proteomic data). This software comes in two varieties. The first variety 
is \textit{high performance software}, where performance is a top priority; 
this kind of software is usually written in a programming language like C or 
C++. The second variety is software where performance is not a top priority; 
this kind of software written in higher-level languages that emphasize 
convenience and programmer productivity, such as Perl, Python, Ruby, or R.

In this Experience Report, we show that the Haskell programming language is an 
excellent alternative for computational biologists: a Haskell program can 
perform comparably to a C++ program while being as flexible and easy to 
understand as a program written in an interpreted language. Our experience is 
based on an implementation of a novel algorithm for finding remote homologs to 
newly discovered proteins. We call this program MRFy.

As a brief refresher in the standard dogma of genetics, recall that genes 
(strands of deoxyribonucleic acid (DNA), which are sequences of the nucleotides 
adenosine, cytosine, guanine, and thymine, represented by the letters A, C, G, 
and T) are transcribed into ribonucleic acid (RNA). Some RNA is then translated 
into the 20 naturally-occuring amino acids, which form peptide chains -- 
proteins -- which fold into complex structures in the cell. These proteins are 
cellular machinery, performing the varied functions an organism needs to 
survive. 

However, determining what newly sequenced genes actually do -- when they become 
proteins, what structures those proteins fold into, and what functions they 
perform -- has not kept pace. Determining the atomic coordinates of a newly 
discovered protein may require as much as two graduate-student-years in a lab! 
Fortunately, determining the full structure of a protein is not always 
necessary. Often, we can identify well-known proteins of similar sequence or 
structure to a new protein, and thus make educated guesses as to the structure 
and function of the new protein.

The problem of taking a newly found protein sequence about which only the 
sequence is known, and determining what existing proteins of known structure 
and function most closely resemble that new protein, is known as homology 
detection. When proteins of similar sequence can be found, this problem is 
largely solved. To solve the homology detection problem, computational 
biologists have developed fast, approximate methods for determining the 
structure and function of proteins based on their sequence. The most popular 
software for homology detection is called HMMER, which uses a hidden Markov 
model to capture evolutionary change.

However, when there are no known proteins of similar sequence, only 
evolutionarily distant proteins that may share similar structure, this problem 
is called remote homology detection. Hidden Markov model approaches begin to 
fail as sequence similarity falls off. Recently, Markov random field 
approaches, which capture non-local interactions in the protein structure, have 
been shown to perform well. However, these approaches face the challenge of 
increased computational complexity; the SMURF program exhibits exponential time 
complexity, while SMURFLite (work by one of the authors) bounds the exponent by 
simplifying the Markov random field's dependency graph. MRFy is a 
stochastic search approach to Markov random fields.

SMURF, SMURFLite, and MRFy all attempt to compute the optimal parse, or 
alignment, of a protein sequence onto the directed graph representing a Markov 
random field (see Figure \ref{mrf}). A parse is a mapping of the letters of a 
query sequence onto the states of a markov Random field, while an optimal parse 
is the parse exhibiting the greatest probability once. The algorithm underlying 
MRFy grew out of an understanding of the limitations of the SMURF (Structural 
Motifs Using Random Fields) algorithm, which used multidimensional dynamic 
programming to compute the optimal parse of a query sequence onto a Markov 
random field. Rather than attempt to compute exactly the optimal parse, MRFy 
treats the non-local interactions (which correspond to hydrogen-bonded ``beta 
strands'' in the protein) as ``beads'' which can be slid along a string. In 
this analogy, the string is the sequence of amino acids of the query protein. A 
given placement of these beads corresponds to an assignment of particular amino 
acid residues being hydrogen bonded to other particular amino acid residues, 
and thus MRFy computes a probability based on observed frequencies of residues 
hydrogen bonding in beta strands~\cite{betawrappro}. In between these beta 
strands, the Markov random field is in fact a traditional hidden Markov model, 
whose optimal solution can be easily computed via dynamic programming (known as 
the Viterbi algorithm). MRFy performs a stochastic search to place these beta 
strands, based on an objective function that combines the probability computed 
by the Viterbi algorithm with that computed from the paired, hydrogen-bonded 
residues in the beta strands.




\begin{figure} 
\centerline{\includegraphics[width=8cm]{mrf_interleave_diagram.pdf}} 
\caption{The directed graph representing the states of a MRFy Markov random 
field finite state automaton. Shaded nodes represent beta-strand positions, 
while the dashed edges represent the long-range dependencies due to hydrogen 
bonding.}\label{mrf} \end{figure}



\subsection{Our Background}

All three authors are members of the Tufts University Department of Computer 
Science. Noah Daniels has taken a graduate seminar in advanced functional 
programming, which included some Haskell, and spent ten years in industry as a 
professional programmer in languages such as Ruby, C, and C++. Andrew Gallant 
has taken a programming languages course heavily focused on functional 
programming, but with no Haskell. Norman Ramsey is the local expert, but he 
wrote no code for this project.

\section{What we did}

\subsection{Beautiful code}
MRFy contains two distinct algorithms: the classical Viterbi 
dynamic-programming algorithm for hidden Markov models, and a stochastic search 
algorithm for placing beta-strand positions. This stochastic search algorithm 
implements several search heuristics: random-mutation hill climbing, simulated 
annealing, multistart simulated annealing, and a genetic algorithm.



The Viterbi algorithm~\cite{Viterbi:1967} comprises a set of recurrence 
relations (see Equation \ref{viterbi_eqn}) that seek to maximize the 
probability of an observed sequence (in this case, of amino acid ``letters'') 
being emitted by a particular finite-state automaton (the hidden Markov model). 
The particular states of this finite-state automaton map to the recurrence 
relations, and in this instance derive from what is known in the computational 
biology community as a \textit{profile} hidden Markov model. The Viterbi 
algorithm in this instance recurses on ``insertion,'' ``deletion,'' and 
``match'' states (Figure~\ref{plan7}). Insertion states represent mutations 
that gain an amino acid letter in the query sequence, deletion states represent 
mutations that lose an amino acid letter in the query sequence, and match 
states represent either conserved positions (no change) or mutations that 
substitute one amino acid for another. The match and insertion states each have 
an associated table of emission probabilities, determined during training, 
indicating how likely that state is to emit a particular amino acid letter. 
Edges from state to state represent state transitions, and have associated 
probabilities determined during training. To be efficient, the Viterbi 
algorithm relies on dynamic programming, or memoization, and the resulting 
asymptotic complexity is $O(|M|\times|N|)$, when $M$ is the sequence of 
distinct states (nodes in the automaton's graph) and $N$ is the sequence of 
letters in the protein sequence. In our particular problem domain, both $M$ and 
$N$ routinely contain several hundred to a few thousand elements. The types of 
these states and probabilities are provided in Figure~\ref{viterbi_types}.


\begin{figure*}
\lstinputlisting[label=viterbi_types,caption=Viterbi Types]{viterbi_types.hs}
\end{figure*}


\begin{figure} \centerline{\includegraphics[width=8cm]{Plan7.pdf}} \caption{The 
directed graph representing the states of a traditional HMMER ``Plan7'' hidden 
Markov model. Only 7 of the possible 9 state transitions are allowed, which 
simplifies the dynamic programming. Insertion states represent mutations that 
insert an amino acid, deletion states represent mutations that lose an amino 
acid, and match states represent either conserved amino acids (those with no 
changes) or mutations that substitute one amino acid for another. Each match or 
insertion state has an associated table of emission probabilities (here 
illustrated only for the first two states)}\label{plan7} \end{figure}


The textbook Viterbi recurrence relations refer to logs of probabilities, so 
that the terms may be added rather than multiplying raw probabilities. For 
reasons including floating point underflow, the HMMER software (with which we 
maintain file format compatibility) stores all probabilities in a trained HMM 
file as negative natural logs. Thus, the Viterbi recurrence relations are 
simplified from the form in \ref{viterbi_eqn} to that in \ref{viterbi_log_eqn}, 
and because they are \textit{negative} logs, the problem transforms from 
maximization to minimization.


\begin{eqnarray}    
V_{j}^{M}(i) = \log\frac{e_{M_{j}}(x_{i})}{q_{x_{i}}} + max \left\{
\begin{array}{l l}
V_{j-1}^{M}(i - 1) + \log a_{M_{j-1}M_{j}},\\
V_{j-1}^{I}(i - 1) + \log a_{I_{j-1}M_{j}},\\
V_{j-1}^{D}(i - 1) + \log a_{D_{j-1}M_{j}}\\
\end{array} \right.\nonumber\\
V_{j}^{I}(i) = \log\frac{e_{I_{j}}(x_{i})}{q_{x_{i}}} + max \left\{
\begin{array}{l l}
V_{j-1}^{M}(i - 1) + \log a_{M_{j-1}I_{j}},\\
V_{j-1}^{I}(i - 1) + \log a_{I_{j-1}I_{j}},\\
\end{array} \right.\nonumber\\
V_{j}^{D}(i) = max \left\{
\begin{array}{l l}
V_{j-1}^{M}(i - 1) + \log a_{M_{j-1}D_{j}},\\
V_{j-1}^{D}(i - 1) + \log a_{D_{j-1}D_{j}}\\
\end{array} \right.\nonumber\\
\end{eqnarray}\label{viterbi_eqn}

\begin{eqnarray}    
V_{j}^{\prime M}(i) = e^{\prime}_{M_{j}}(x_{i}) + min \left\{
\begin{array}{l l}
V_{j-1}^{\prime M}(i - 1) + a^{\prime}_{M_{j-1}M_{j}},\\
V_{j-1}^{\prime I}(i - 1) + a^{\prime}_{I_{j-1}M_{j}},\\
V_{j-1}^{\prime D}(i - 1) + a^{\prime}_{D_{j-1}M_{j}}\\
\end{array} \right.\nonumber\\
V_{j}^{\prime I}(i) = e^{\prime}_{I_{j}}(x_{i}) + min \left\{
\begin{array}{l l}
V_{j-1}^{\prime M}(i - 1) + a^{\prime}_{M_{j-1}I_{j}},\\
V_{j-1}^{\prime I}(i - 1) + a^{\prime}_{I_{j-1}I_{j}},\\
\end{array} \right.\nonumber\\
V_{j}^{\prime D}(i) = min \left\{
\begin{array}{l l}
V_{j-1}^{\prime M}(i - 1) + a^{\prime}_{M_{j-1}D_{j}},\\
V_{j-1}^{\prime D}(i - 1) + a^{\prime}_{D_{j-1}D_{j}}\\
\end{array} \right.\nonumber\\
\text{where } a^{\prime}_{s} = - \log a_{s} \nonumber \\
\text{and } e^{\prime}_{s,x} = - \log\frac{e_{s,x}}{q_{x}} \nonumber
\end{eqnarray}\label{viterbi_log_eqn}


\begin{figure*}
\lstinputlisting[label=viterbi,caption=Viterbi]{viterbi_simple.hs}
\end{figure*}


We implemented the Viterbi algorithm in two distinct ways. We first wrote a 
bottom-up dynamic-programming version, which began with the first node of the 
hidden Markov model and first observation and built up the three-dimensional 
array of possible paths through the model. The array containing the paths 
served as the memoization table. We next wrote a top-down dynamic-programming 
version, which began with the last node of the model and the last observation, 
and applied structural recursion down to the base cases involving the first 
node or first observation (or both). In this second approach, we used the 
\texttt{Data.Memocombinators} library to provide the memoization container 
(again, a three-dimensional array). We determined that the run-time 
performances of both approaches were virtually indistinguishable, and we also 
noted that the top-down version quite faithfully resembled the recurrence 
relations found in a textbook~\cite{durbin} or the HMMER literature~\cite{eddy} 
(see Equation \ref{viterbi_eqn}). We chose to keep the top-down version, which 
later proved to be wise when we had to track down a bug in one of our base 
cases. This bug was observed as a missing state in the alignment our program 
displayed, and we quickly discovered that one of our base cases was missing 
this state: it was returning an empty list as the base of the path, rather than 
a list containing a single node. In this, we were grateful for the resemblance 
between the mathematical description of the algorithm and the top-down 
dynamic-programming approach in Haskell, which resulted in perspicuous code.





Just as the Viterbi algorithm is one major component of MRFy, stochastic search 
is the other. In designing MRFy, we did not know in advance what sort of 
stochastic search technique would converge the fastest, or give us the best 
alignments with the fastest performance. We decided to implement several 
different search strategies so that we could experiment with all of them. We 
found this to be easy and pleasant thanks to Haskell's support of higher order 
functions.

We wrote a basic search function in only twenty-two lines of code; as one of 
its parameters we provide a \texttt{SearchStrategy} data type, which we use to 
define specific search techniques. We require a \texttt{SearchStrategy} to 
define four functions: \texttt{mutate}, \texttt{accept}, \texttt{terminate}, 
and \texttt{initialize}; we use the Haskell module system to allow sharing of 
some of these functions between different search strategies. For example, both 
\textit{random mutation hill climb} and \textit{simulated annealing} use the 
same initialize and mutate functions, but very different accept functions. In 
all, we implemented four search strategies: \textit{random mutation hill 
climb}, \textit{simulated annealing}, \textit{multistart simulated annealing}, 
and \textit{genetic algorithm}. We found the implementation of the search 
function and search strategies to be pleasant, and the resulting code to be 
simple and elegant. In an imperative language with object orientation like Ruby 
or Python, we likely would have used a class hierarchy to accomplish this. We 
feel that this would have required more code, because object orientation is 
meant for encapsulating data as well as functions on those data; here we only 
wanted to encapsulate functions, as the data did not change.


We note that \texttt{seed} in \texttt{search} comes from a monadic random 
number generator in Main, but we wished for search itself to be pure at this 
level. One advantage is that this allows for testing of the \texttt{search} 
function with no randomness at all: if we pass in a known number as the seed, 
behavior is entirely deterministic.


\begin{figure*}
\lstinputlisting[label=search,caption=Search]{search_simple.hs}
\end{figure*}

In MRFy, the Viterbi function is called several times (once for each 
non-beta-strand region) for each search generation. Furthermore, in a 
population-based search such as \textit{multistart simulated annealing}, the 
scoring function (which itself calls Viterbi) is called many times per 
generation. Beyond traditional profiling, we found parallelization to be an 
obvious way to improve runtime performance. We found this to be trivial thanks 
to the \texttt{Control.Parallel} library. We pass the Viterbi function to a map over all 
non-beta-strand regions of the model and query sequence, and these regions are 
independent of one another. Similarly, we pass the scoring function to a map 
over the population of potential solutions, which are also independent. We 
merely substituted \texttt{parmap rseq} for map. MRFy now efficiently uses all six 
cores on an AMD workstation for a non-population-based simulated annealing 
search, and all forty-eight cores on a compute server for population-based 
searches.


\subsection{Ugly code}


Despite the beauty of some of the code we were able to write, we found several 
instances where the easiest path seemed to be to write ugly code. The first of 
these relates to the otherwise elegant Viterbi function. Our stochastic search 
approach calls the Viterbi function a tremendous number of times, and most of 
the program's runtime is spent in this function. However, the Viterbi algorithm 
retains not just a score (the probability of the sequence given a state path) 
but also the state path itself. We implemented this state path as a list of 
\texttt{Int}, and every step in the recursion conses a new element onto the 
list. However, at each step of the stochastic search, we discard the state 
path; we are searching to optimize score only. We only need the state path at 
the termination of the search, when we wish the program to output an alignment 
of the query sequence to the Markov random field model. We found that 
optimizing the Viterbi function by removing this state path entirely improved 
runtime performance by nearly 50\%. However, we still needed the Viterbi 
function to provide a state path when we called it after search finally 
terminated. Thus, we wondered how to implement the Viterbi function so that a 
state path was optional.

In order to determine if this optimization was even worthwhile, we first wrote 
a quick and dirty approach that is shameful in any language, but easy: we 
duplicated code. We copied \texttt{viterbi} to produce a \texttt{viterbiF} 
which did not retain state path. Next, however, we wondered how to avoid code 
duplication. Clearly, littering the code with conditionals would produce code 
that was ugly as well as less efficient. We knew how we would solve this 
problem in other languages; we would have used macros in Lisp, or 
metaprogramming via \texttt{eval} in Ruby, to produce two versions of the 
function from one prototype. We struggled, however, to solve this problem 
idiomatically in Haskell.

Rather than attempt to use \texttt{TemplateHaskell} to generate two versions of 
the Viterbi function, we wrote a higher-order function type 
\lstinline!type ScorePathCons a = a -> [a] -> [a]! and two functions conforming to that type. 
Then, depending on whether \texttt{viterbi} was called with \texttt{consPath} 
or \texttt{consNoPath} as a parameter, the path would or would not be 
allocated. We found this higher-order function approach to be simple in code 
and in concept, and it imposes negligible run-time overhead as compared to 
having two distinct functions.

\lstinputlisting[label=scorepathcons,caption=ScorePathCons]{scorepathcons.hs}

Another source of ugliness resulted from adding cost-center annotations when we 
wished to profile our code. GHC will happily add cost centers to top-level 
functions, but much of our program relies on sub-functions. We found that 
manually adding \texttt{\{-SCC -\}} annotations to dozens of guard clauses and 
sub-functions harmed the readability of our program, such that we felt 
compelled to remove all such annotations as soon as we could. In our prior 
experience with profiling tools such as kcachegrind, simply compiling with 
debug symbols -- rather than manually annotating many lines of code -- allowed 
the profiling tools to provide us enough information. Without these 
annotations, both call-site and allocation profiles are relatively useless in 
GHC. Perhaps a compile-time flag that would auto-annotate every equation -- 
even if the resulting cost center is simply named with a line number -- would 
make this task easier.

The final source of ugliness in our code came from attempts at debugging 
run-time errors. MRFy relies on a source of input data -- the paired beta 
strands in the Markov random field -- which is represented in an awkward manner 
by the original SMURF program, and which is outside our control. Rather than 
represent beta strands directly, SMURF represents pairings of residues, leaving 
us to infer and reconstruct beta strands. This task was difficult due to 
unclear invariants around overlapping, doubly-paired beta strands (and it would 
have been difficult in any programming language; the difficulty was one of 
representation). However, the debugging tools in GHC caused us some 
difficulties in determining the sources of run-time errors. We used 
\texttt{trace} extensively, but this style of ``\texttt{printf} debugging'' 
littered our code. Being initially unaware of the backtrace feature of the GHC 
profiler, we wrote wrappers around \texttt{Vector.slice} and \texttt{Vector.!} 
which themselves called trace, which at least kept our ``\texttt{printf} 
debugging'' less cluttered. Nonetheless, we struggled with these runtime errors 
due to an awkward representation, and wished for debugging tools such as we 
might find in gdb, which would allow us to examine the stack when a backtrace 
occurs.
 
 
\section{Our previous code base compared}

Haskell makes it difficult to write code in haste, because Haskell militates towards careful type-checking and clearly thought-out function contracts. Unlike dynamic languages such as Ruby, and unlike C++, Haskell punishes the programmer who attempts to write code quickly with the goal of later making it work correctly. We have found MRFy to be easier to enhance and maintain than our existing C++ code bases.
 
\section{State of the practice}

\subsection{Our group then}
 - Modifying Formatt took nearly a year
 - mutable data structures hard to repurpose
 - one enhancement deemed infeasible
 - C++ failures most commonly segfaults, memory errors, heap exhaustion

\subsection{Our group now}
 - Higher order functions militate towards more flexibility
 - Haskell failures are usually typecheck failures; at worst runtime errors around bounds checking
 - MRFy about 3 months of part-time work

\subsection{Computational biology at large}
 - some good software, like HMMER

\section{What we think about it}

\subsection{Barriers}

- profiling
- debugging
 [ talk about profiling and debugging problems where?]
[ something about quickcheck: how do we know when we have enough QC props? How do we start testing a complex module? ]

\subsection{What you must know to succeed}
- Ecosystem is loaded with tools that look promising but either are no longer maintained or are not ready for prime time (Pads, Backtrace)

\subsection{Evaluation}
- What does the local expert do? Do you have to have one?

- To the FP community: Those who want us to abandon our old tools for debugging imperative code have not provided a clear path to follow (both intellectually, and via software tools).

- No obvious body of knowledge on code improvement.

- The ecosystem contains tools that look promising and work great: Data.Memocombinators, Quickcheck, Parallel Strategies. How to tell what's good? How did we discover what's good?
- Profiler can produce backtraces, but this was hard to discover.

% \appendix
% \section{Appendix Title}
% 
% This is the text of the appendix, if you need one.

\acks

We thank Lenore Cowen, Kathleen Fisher, Benjamin Hescott, Bradford Larsen, and Nathan Ricci.

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrvnat}

% The bibliography should be embedded for final submission.

\begin{thebibliography}{}
\softraggedright

\bibitem[Smith et~al.(2009)Smith, Jones]{smith02}
P. Q. Smith, and X. Y. Jones. ...reference text...

\end{thebibliography}

\end{document}
