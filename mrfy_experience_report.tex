
\documentclass[preprint]{sigplanconf}

% The following \documentclass options may be useful:
%
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.

\usepackage{amsmath}
\usepackage{array}
\usepackage{listings}
\lstset{
    tabsize = 2,
    basicstyle = \ttfamily,
    language = Haskell
    }    

\begin{document}


\conferenceinfo{ICFP '12}{date, City.} 
\copyrightyear{2012} 
\copyrightdata{[to be supplied]} 

\titlebanner{banner above paper title}        % These are ignored unless
\preprintfooter{short description of paper}   % 'preprint' option specified.

\title{Experience Report: Haskell in Computational Biology}
\subtitle{Subtitle Text, if any}

\authorinfo{Noah M. Daniels \and Andrew Gallant \and Norman Ramsey}
           {Department of Computer Science, Tufts University}
           {\{ndaniels, agallant, nr\}@cs.tufts.edu}


\maketitle

\begin{abstract}
This is the text of the abstract.
\end{abstract}

\category{CR-number}{subcategory}{third-level}

\terms
term1, term2

\keywords
keyword1, keyword2

\section{Introduction}

We address this paper to computational biologists who may have an interest in 
functional programming, but this is not an advocacy paper. We do not argue that 
computational biologists \textit{should} use functional programming. Rather, 
argue that computational biologists \textit{can} successfully develop software 
in Haskell, and what to expect if they do.

We also address this paper to the functional programming community, in the 
hopes that our experiences will be enlightening. We believe that our 
experiences can provide lessons about outreach and education.


\subsection{Problem Domain}

Computational biologists write software to solve problems on large genomic or 
proteomic data sets. Traditionally, these software programs fall into two 
categories: those with high-performance computing needs are typically 
implemented in C++, while the remainder are typically implemented in Perl, 
Python, Ruby, or R. Recently, we have developed a program in Haskell which 
implements a novel algorithm for solving the remote homology detection problem. 
While designing the algorithm, we wondered: would the algorithm be easily 
expressed in Haskell? Would we be able to achieve acceptable runtime 
performance? How would our experience compare with our past experiences 
developing and maintaining computational biology software in C++, Ruby, and 
Python? What would be our greatest challenges? In this paper, we briefly 
explain the remote homology detection problem and our algorithm, and then 
attempt to answer the above questions.

As a brief refresher in the standard dogma of genetics, recall that genes 
(strands of deoxyribonucleic acid (DNA), which are sequences of the nucleotides 
adenosine, cytosine, guanine, and thymine, represented by the letters A, C, G, 
and T) are transcribed into ribonucleic acid (RNA). Some RNA is then translated 
into the 20 naturally-occuring amino acids, which form peptide chains -- 
proteins -- which fold into complex structures in the cell. These proteins are 
cellular machinery, performing the varied functions an organism needs to 
survive. Since the dawn of the human genome project in 1990, the cost of 
sequencing an entire genome has dropped exponentially. Recently, the doubling 
time for genomic data has been one year, in contrast to the eighteen month 
doubling time of Moore's law. However, determining what newly sequenced genes 
actually do -- when they become proteins, what structures those proteins fold 
into, and what functions they perform -- has not kept pace. Determining the 
atomic coordinates of a newly discovered protein may require as much as two 
graduate-student-years in a lab!

The problem of taking a newly found protein sequence about which only the 
sequence is known, and determining what existing proteins of known structure 
and function most closely resemble that new protein, is known as homology 
detection. When proteins of similar sequence can be found, this problem is 
largely solved. To solve the homology detection problem, computational 
biologists have developed fast, approximate methods for determining the 
structure and function of proteins based on their sequence. The most popular 
software for homology detection is called HMMER, which uses a hidden Markov 
model to capture evolutionary change.

However, when there are no known proteins of similar sequence, only 
evolutionarily distant proteins that may share similar structure, this problem 
is called remote homology detection. Hidden Markov model approaches begin to 
fail as sequence similarity falls off. Recently, Markov random field 
approaches, which capture non-local interactions in the protein structure, have 
shown to perform well. However, these approaches face the challenge of 
increased computational complexity; the SMURF program exhibits exponential time 
complexity, while SMURFLite (work by one of the authors) bounds the exponent by 
simplifying the Markov random field's dependency graph. We have implemented a 
stochastic search approach to Markov random fields, called MRFy.

The algorithm underlying MRFy grew out of an understanding of the limitations 
of the SMURF (Structural Motifs Using Random Fields) algorithm, which used 
multidimensional dynamic programming to compute the optimal parse of a query 
sequence onto a Markov random field.


TODO: (add explanation of MRFy architecture and algorithm)

\subsection{Our Background}

All three authors are members of the Tufts University Department of Computer 
Science. Noah Daniels has taken a graduate seminar in advanced functional 
programming, which included some Haskell, and spent ten years in industry as a 
professional programmer in languages such as Ruby, C, and C++. Andrew Gallant 
has taken a programming languages course heavily focused on functional 
programming, but with no Haskell. Norman Ramsey is the local expert, but he 
wrote no code for this project.

\section{What we did}

\subsection{Beautiful code}
MRFy contains two distinct algorithms: the classical Viterbi dynamic 
programming algorithm for hidden Markov models, and a stochastic search 
algorithm for placing beta strand positions. This stochastic search algorithm 
implements several search heuristics: random-mutation hill climbing, simulated 
annealing, multistart simulated annealing, and a genetic algorithm.


The Viterbi algorithm~\cite{Viterbi:1967} comprises a set of recurrence 
relations that seek to maximize the probability of an observed sequence (in 
this case, of amino acid ``letters'') being emitted by a particular 
finite-state automaton (the hidden Markov model). The particular states of this 
finite-state automaton map to the recurrence relations, and in this instance 
derive from what is known in the computational biology community as a 
\textit{profile} hidden Markov model. The Viterbi algorithm in this instance 
recurses on ``match,'' ``insertion,'' and ``deletion'' states. To be efficient, 
the Viterbi algorithm relies on dynamic programming, or memoization, and the 
resulting asymptotic complexity is $O(|M|\times|N|)$, when $M$ is the sequence 
of distinct states (nodes in the automaton's graph) and $N$ is the sequence of 
letters in the protein sequence. In our particular problem domain, both $M$ and 
$N$ routinely contain several hundred to a few thousand elements.

\begin{eqnarray}    
V_{j}^{M}(i) = \log\frac{e_{M_{j}}(x_{i})}{q_{x_{i}}} + max \left\{
\begin{array}{l l}
V_{j-1}^{M}(i - 1) + \log a_{M_{j-1}M_{j}},\\
V_{j-1}^{I}(i - 1) + \log a_{I_{j-1}M_{j}},\\
V_{j-1}^{D}(i - 1) + \log a_{D_{j-1}M_{j}}\\
\end{array} \right.\nonumber\\
V_{j}^{I}(i) = \log\frac{e_{I_{j}}(x_{i})}{q_{x_{i}}} + max \left\{
\begin{array}{l l}
V_{j-1}^{M}(i - 1) + \log a_{M_{j-1}I_{j}},\\
V_{j-1}^{I}(i - 1) + \log a_{I_{j-1}I_{j}},\\
\end{array} \right.\nonumber\\
V_{j}^{D}(i) = max \left\{
\begin{array}{l l}
V_{j-1}^{M}(i - 1) + \log a_{M_{j-1}D_{j}},\\
V_{j-1}^{D}(i - 1) + \log a_{D_{j-1}D_{j}}\\
\end{array} \right.\nonumber\\
\end{eqnarray}\label{viterbi_eqn}



We implemented the Viterbi algorithm in two distinct ways. We first wrote a 
bottom-up dynamic programming version, which began with the first node of the 
hidden Markov model and first observation and built up the three-dimensional 
array of possible paths through the model. The array containing the paths 
served as the memoization table. We next wrote a top-down dynamic programming 
version, which began with the last node of the model and the last observation, 
and applied structural recursion down to the base cases involving the first 
node or first observation (or both). In this second approach, we used the 
\texttt{Data.Memocombinators} library to provide the memoization container 
(again, a three-dimensional array). We determined that the run-time 
performances of both approaches were virtually indistinguishable, and we also 
noted that the top-down version quite faithfully resembled the recurrence 
relations found in a textbook~\cite{durbin} or the HMMER literature~\cite{eddy} 
(see Equation \ref{viterbi_eqn}). We chose to keep the top-down version, which 
later proved to be wise when we had to track down a bug in one of our base 
cases. This bug was observed as a missing state in the alignment our program 
displayed, and we quickly discovered that one of our base cases was missing 
this state: it was returning an empty list as the base of the path, rather than 
a list containing a single node. In this, we were grateful for the resemblance 
between the mathematical description of the algorithm and the top-down dynamic 
programming approach in Haskell, which resulted in perspicuous code.


\begin{figure*}
\lstinputlisting[label=viterbi,caption=Viterbi]{viterbi_simple.hs}
\end{figure*}

Just as the Viterbi algorithm is one major component of MRFy, stochastic search 
is the other. In designing MRFy, we did not know in advance what sort of 
stochastic search technique would converge the fastest, or give us the best 
alignments with the fastest performance. We decided to implement several 
different search strategies so that we could experiment with all of them. We 
found this to be easy and pleasant thanks to Haskell's support of higher order 
functions.

We wrote a basic search function in only twenty-two lines of code; as one of 
its parameters we provide a \texttt{SearchStrategy} data type, which we use to 
define specific search techniques. We require a \texttt{SearchStrategy} to 
define four functions: \texttt{mutate}, \texttt{accept}, \texttt{terminate}, 
and \texttt{initialize}; we use the Haskell module system to allow sharing of 
some of these functions between different search strategies. For example, both 
\textit{random mutation hill climb} and \textit{simulated annealing} use the 
same initialize and mutate functions, but very different accept functions. In 
all, we implemented four search strategies: \textit{random mutation hill 
climb}, \textit{simulated annealing}, \textit{multistart simulated annealing}, 
and \textit{genetic algorithm}. We found the implementation of the search 
function and search strategies to be pleasant, and the resulting code to be 
simple and elegant. In an imperative language with object orientation like Ruby 
or Python, we likely would have used a class hierarchy to accomplish this. We 
feel that this would have required more code, because object orientation is 
meant for encapsulating data as well as functions on those data; here we only 
wanted to encapsulate functions, as the data did not change.


\begin{figure*}
\lstinputlisting[label=search,caption=Search]{search_simple.hs}
\end{figure*}

In MRFy, the Viterbi function is called several times (once for each 
non-beta-strand region) for each search generation. Furthermore, in a 
population-based search such as \textit{multistart simulated annealing}, the 
scoring function (which itself calls Viterbi) is called many times per 
generation. Beyond traditional profiling, we found parallelization to be an 
obvious way to improve runtime performance. We found this to be trivial thanks 
to the \texttt{Control.Parallel} library. We pass the Viterbi function to a map over all 
non-beta-strand regions of the model and query sequence, and these regions are 
independent of one another. Similarly, we pass the scoring function to a map 
over the population of potential solutions, which are also independent. We 
merely substituted \texttt{parmap rseq} for map. MRFy now efficiently uses all six 
cores on an AMD workstation for a non-population-based simulated annealing 
search, and all forty-eight cores on a compute server for population-based 
searches.


\subsection{Ugly code}


Despite the beauty of some of the code we were able to write, we found several 
instances where the easiest path seemed to be to write ugly code. The first of 
these relates to the otherwise elegant Viterbi function. Our stochastic search 
approach calls the Viterbi function a tremendous number of times, and most of 
the program's runtime is spent in this function. However, the Viterbi algorithm 
retains not just a score (the probability of the sequence given a state path) 
but also the state path itself. We implemented this state path as a list of 
\texttt{Int}, and every step in the recursion conses a new element onto the 
list. However, at each step of the stochastic search, we discard the state 
path; we are searching to optimize score only. We only need the state path at 
the termination of the search, when we wish the program to output an alignment 
of the query sequence to the Markov random field model. We found that 
optimizing the Viterbi function by removing this state path entirely improved 
runtime performance by nearly 50\%. However, we still needed the Viterbi 
function to provide a state path when we called it after search finally 
terminated. Thus, we wondered how to implement the Viterbi function so that a 
state path was optional.

In order to determine if this optimization was even worthwhile, we first wrote 
a quick and dirty approach that is shameful in any language, but easy: we 
duplicated code. We copied \texttt{viterbi} to produce a \texttt{viterbiF} 
which did not retain state path. Next, however, we wondered how to avoid code 
duplication. Clearly, littering the code with conditionals would produce code 
that was ugly as well as less efficient. We knew how we would solve this 
problem in other languages; we would have used macros in Lisp, or 
metaprogramming via \texttt{eval} in Ruby, to produce two versions of the 
function from one prototype. We struggled, however, to solve this problem 
idiomatically in Haskell.

Rather than attempt to use \texttt{TemplateHaskell} to generate two versions of 
the Viterbi function, we wrote a higher-order function type 
\lstinline!type ScorePathCons a = a -> [a] -> [a]! and two functions conforming to that type. 
Then, depending on whether \texttt{viterbi} was called with \texttt{consPath} 
or \texttt{consNoPath} as a parameter, the path would or would not be 
allocated. We found this higher-order function approach to be simple in code 
and in concept, and it imposes negligible run-time overhead as compared to 
having two distinct functions.

\lstinputlisting[label=scorepathcons,caption=ScorePathCons]{scorepathcons.hs}

Another source of ugliness resulted from adding cost-center annotations when we 
wished to profile our code. GHC will happily add cost centers to top-level 
functions, but much of our program relies on sub-functions. We found that 
manually adding \texttt{\{-SCC -\}} annotations to dozens of guard clauses and 
sub-functions harmed the readability of our program, such that we felt 
compelled to remove all such annotations as soon as we could. In our prior 
experience with profiling tools such as kcachegrind, simply compiling with 
debug symbols -- rather than manually annotating many lines of code -- allowed 
the profiling tools to provide us enough information. Without these 
annotations, both call-site and allocation profiles are relatively useless in 
GHC. Perhaps a compile-time flag that would auto-annotate every equation -- 
even if the resulting cost center is simply named with a line number -- would 
make this task easier.

The final source of ugliness in our code came from attempts at debugging 
run-time errors. MRFy relies on a source of input data -- the paired beta 
strands in the Markov random field -- which is represented in an awkward manner 
by the original SMURF program, and which is outside our control. Rather than 
represent beta strands directly, SMURF represents pairings of residues, leaving 
us to infer and reconstruct beta strands. This task was difficult due to 
unclear invariants around overlapping, doubly-paired beta strands (and it would 
have been difficult in any programming language; the difficulty was one of 
representation). However, the debugging tools in GHC caused us some 
difficulties in determining the sources of run-time errors. We used 
\texttt{trace} extensively, but this style of ``\texttt{printf} debugging'' 
littered our code. Being initially unaware of the backtrace feature of the GHC 
profiler, we wrote wrappers around \texttt{Vector.slice} and \texttt{Vector.!} 
which themselves called trace, which at least kept our ``\texttt{printf} 
debugging'' less cluttered. Nonetheless, we struggled with these runtime errors 
due to an awkward representation, and wished for debugging tools such as we 
might find in gdb, which would allow us to examine the stack when a backtrace 
occurs.
 
 
\section{Our previous code base compared}

 - SMURF bad
 - HMMER good
 
\section{State of the practice}

\subsection{Our group then}
 - Modifying Formatt took nearly a year
 - mutable data structures hard to repurpose
 - one enhancement deemed infeasible
 - C++ failures most commonly segfaults, memory errors, heap exhaustion

\subsection{Our group now}
 - Higher order functions militate towards more flexibility
 - Haskell failures are usually typecheck failures; at worst runtime errors around bounds checking
 - MRFy about 3 months of part-time work

\subsection{Computational biology at large}
 - some good software, like HMMER

\section{What we think about it}

\subsection{Barriers}

- profiling
- debugging
 [ talk about profiling and debugging problems where?]
[ something about quickcheck: how do we know when we have enough QC props? How do we start testing a complex module? ]

\subsection{What you must know to succeed}
- Ecosystem is loaded with tools that look promising but either are no longer maintained or are not ready for prime time (Pads, Backtrace)

\subsection{Evaluation}
- What does the local expert do? Do you have to have one?

- To the FP community: Those who want us to abandon our old tools for debugging imperative code have not provided a clear path to follow (both intellectually, and via software tools).

- No obvious body of knowledge on code improvement.

- The ecosystem contains tools that look promising and work great: Data.Memocombinators, Quickcheck, Parallel Strategies. How to tell what's good? How did we discover what's good?
- Profiler can produce backtraces, but this was hard to discover.

\appendix
\section{Appendix Title}

This is the text of the appendix, if you need one.

\acks

Acknowledgments, if needed.

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrvnat}

% The bibliography should be embedded for final submission.

\begin{thebibliography}{}
\softraggedright

\bibitem[Smith et~al.(2009)Smith, Jones]{smith02}
P. Q. Smith, and X. Y. Jones. ...reference text...

\end{thebibliography}

\end{document}
